{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>neck</th>\n",
       "      <th>sleeve_length</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdc8cd2a-0938-4970-a3b5-f5ed9595222c1527925869...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11469770662809-Metersbonwe-Navy-T-shirt-485146...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11479107741104-Tommy-Hilfiger-Men-Navy-Blue-St...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f7ad67ab-eeb1-4449-8f63-7b580d2797e71532342804...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11516770810185-Splash-Men-Tshirts-767151677081...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  neck  sleeve_length  \\\n",
       "0  cdc8cd2a-0938-4970-a3b5-f5ed9595222c1527925869...   6.0            NaN   \n",
       "1  11469770662809-Metersbonwe-Navy-T-shirt-485146...   5.0            3.0   \n",
       "2  11479107741104-Tommy-Hilfiger-Men-Navy-Blue-St...   6.0            1.0   \n",
       "3  f7ad67ab-eeb1-4449-8f63-7b580d2797e71532342804...   NaN            0.0   \n",
       "4  11516770810185-Splash-Men-Tshirts-767151677081...   6.0            3.0   \n",
       "\n",
       "   pattern  \n",
       "0      4.0  \n",
       "1      9.0  \n",
       "2      9.0  \n",
       "3      9.0  \n",
       "4      9.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "df=pd.read_csv(\"E:\\\\pytorch\\\\multi_output_classification\\\\classification-assignment\\\\attributes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neck</th>\n",
       "      <th>sleeve_length</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1783.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>1791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.487942</td>\n",
       "      <td>2.543673</td>\n",
       "      <td>8.132887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.069430</td>\n",
       "      <td>0.915810</td>\n",
       "      <td>2.108823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neck  sleeve_length      pattern\n",
       "count  1783.000000    1786.000000  1791.000000\n",
       "mean      4.487942       2.543673     8.132887\n",
       "std       2.069430       0.915810     2.108823\n",
       "min       0.000000       0.000000     0.000000\n",
       "25%       3.000000       3.000000     9.000000\n",
       "50%       6.000000       3.000000     9.000000\n",
       "75%       6.000000       3.000000     9.000000\n",
       "max       6.000000       3.000000     9.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GENERATING DESCRIPTIVE STATISTICS ABOUT THE DATASET\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINITNG THE UNIQUE CATEGORIES INSIDE EACH ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  5. nan  1.  4.  0.  2.  3.]\n",
      "[ 4.  9. nan  8.  6.  1.  3.  7.  2.  0.  5.]\n",
      "[nan  3.  1.  0.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(df.neck.unique())\n",
    "print(df.pattern.unique())\n",
    "print(df.sleeve_length.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALUE COUNT FOR EACH SUB-CATEGORY OF EACH ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    1016\n",
       "1.0     136\n",
       "4.0     134\n",
       "2.0     132\n",
       "5.0     125\n",
       "0.0     125\n",
       "3.0     115\n",
       "Name: neck, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['N'] = df['neck']\n",
    "# df.groupby('neck').count().to_dict(orient='dict')['N']\n",
    "df['neck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1369\n",
       "2.0     148\n",
       "1.0     140\n",
       "0.0     129\n",
       "Name: sleeve_length, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['S'] = df['sleeve_length']\n",
    "# df.groupby('sleeve_length').count().to_dict(orient='dict')['S']\n",
    "df['sleeve_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0    1467\n",
       "6.0      52\n",
       "3.0      46\n",
       "5.0      38\n",
       "4.0      37\n",
       "1.0      37\n",
       "8.0      32\n",
       "7.0      32\n",
       "2.0      29\n",
       "0.0      21\n",
       "Name: pattern, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['P'] = df['pattern']\n",
    "# df.groupby('pattern').count().to_dict(orient='dict')['P']\n",
    "df['pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKING FOR NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename           0\n",
       "neck             455\n",
       "sleeve_length    452\n",
       "pattern          447\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING WHETHER THE IMAGE IS PRESENT IN THE FOLDER OR NOT\n",
    "from pathlib import Path\n",
    "x = []\n",
    "img_path = \"E:\\\\pytorch\\\\multi_output_classification\\\\classification-assignment\\\\images\"\n",
    "for i in range(len(df['filename'])):\n",
    "    ig_path = img_path + '\\\\' + df['filename'][i]\n",
    "    if Path(ig_path).is_file():\n",
    "        continue\n",
    "    else:\n",
    "        x.append(df['filename'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATING THE DATAFRAME WITH VALID IMAGES\n",
    "for i in x:\n",
    "    df = df[df.filename != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename           0\n",
       "neck             372\n",
       "sleeve_length    365\n",
       "pattern          359\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 4)\n"
     ]
    }
   ],
   "source": [
    "# WRITING THE NEW DATAFRAME INTO A CSV FILE\n",
    "print(df.shape)\n",
    "df.to_csv(\"classification-assignment\\\\attributes_v1.csv\",columns=['filename','neck','sleeve_length','pattern'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(\"N\",axis=1,inplace=True)\n",
    "# df.drop(\"S\",axis=1,inplace=True)\n",
    "# df.drop(\"P\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK IF THERE ARE ROWS HAVING ALL VALUES AS NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>neck</th>\n",
       "      <th>sleeve_length</th>\n",
       "      <th>pattern</th>\n",
       "      <th>is_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, neck, sleeve_length, pattern, is_na]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols_to_check=df.columns\n",
    "# df['is_na'] = df[cols_to_check].isnull().apply(lambda x: all(x), axis=1)\n",
    "# df[df['is_na']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROP NAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING THE NAN VALUES SO THAT WE CAN PREDICT THESE NAN VALUES BY BUILDING THE MODEL ON ALL THE VALID VALUES\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"is_na\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11469770662809-Metersbonwe-Navy-T-shirt-485146...</td>\n",
       "      <td>5.0-3.0-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11516770810185-Splash-Men-Tshirts-767151677081...</td>\n",
       "      <td>6.0-3.0-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11461827372049-US-Polo-Assn-Navy-T-shirt-20714...</td>\n",
       "      <td>5.0-3.0-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f617edb8-a874-453b-b6d3-fb860248d5191532955920...</td>\n",
       "      <td>4.0-3.0-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>94b6ab4b-50c9-4d10-847a-4b4482531d651529052514...</td>\n",
       "      <td>6.0-3.0-8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name        label\n",
       "1   11469770662809-Metersbonwe-Navy-T-shirt-485146...  5.0-3.0-9.0\n",
       "4   11516770810185-Splash-Men-Tshirts-767151677081...  6.0-3.0-9.0\n",
       "7   11461827372049-US-Polo-Assn-Navy-T-shirt-20714...  5.0-3.0-9.0\n",
       "9   f617edb8-a874-453b-b6d3-fb860248d5191532955920...  4.0-3.0-9.0\n",
       "12  94b6ab4b-50c9-4d10-847a-4b4482531d651529052514...  6.0-3.0-8.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMBINING ALL ATTRIBUTES TO FORM A TARGET ATTRIBUTE\n",
    "df_new = pd.DataFrame(columns=['name','label'])\n",
    "df_new['label'] = df['neck'].astype(str) +\"-\"+df['sleeve_length'].astype(str)+\"-\"+df['pattern'].astype(str)\n",
    "df_new['name'] = df['filename'].astype(str)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0-3.0-9.0    163\n",
      "1.0-3.0-9.0     82\n",
      "6.0-1.0-9.0     77\n",
      "4.0-3.0-9.0     71\n",
      "6.0-2.0-9.0     67\n",
      "5.0-3.0-9.0     63\n",
      "3.0-3.0-9.0     63\n",
      "0.0-3.0-9.0     60\n",
      "6.0-0.0-9.0     58\n",
      "2.0-3.0-9.0     55\n",
      "6.0-3.0-6.0     26\n",
      "6.0-3.0-3.0     20\n",
      "6.0-3.0-5.0     19\n",
      "6.0-3.0-7.0     16\n",
      "6.0-3.0-2.0     15\n",
      "6.0-3.0-4.0     14\n",
      "6.0-3.0-1.0     14\n",
      "6.0-3.0-8.0     12\n",
      "6.0-3.0-0.0     11\n",
      "Name: label, dtype: int64\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# CHECKING WHETHER THE DATA IS IMBALANCED OR NOT\n",
    "print(df_new['label'].value_counts())\n",
    "print(len(df_new['label'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPPING IMAGES INTO THEIR RESPECTIVE CATEGORY\n",
    "import os\n",
    "import shutil\n",
    "#pth=os.makedirs(\"classification-assignment\\\\train\\\\\")\n",
    "\n",
    "for i in df_new['label'].unique():\n",
    "    if not os.path.exists(\"classification-assignment\\\\train\\\\\"+i):\n",
    "        os.makedirs(\"classification-assignment\\\\train\\\\\"+i)\n",
    "\n",
    "l1=list(df_new['label'])\n",
    "l2=list(df_new['name'])\n",
    "\n",
    "for i in range(len(l1)):\n",
    "    pth_src=\"classification-assignment\\\\images\\\\\"+l2[i]\n",
    "    pth_dst=\"classification-assignment\\\\train\\\\\"+l1[i]+\"\\\\\"+l2[i]\n",
    "    shutil.copyfile(pth_src, pth_dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BALANCING THE DATA BY DATA AUGMENTATION TECHNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification-assignment\\train-exp\n",
      "classification-assignment\\train-exp\\0.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\1.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\2.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\3.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\4.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\5.0-3.0-9.0\n",
      "classification-assignment\\train-exp\\6.0-0.0-9.0\n",
      "classification-assignment\\train-exp\\6.0-1.0-9.0\n",
      "classification-assignment\\train-exp\\6.0-2.0-9.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-0.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-1.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-2.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-3.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-4.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-5.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-6.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-7.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-8.0\n",
      "classification-assignment\\train-exp\\6.0-3.0-9.0\n"
     ]
    }
   ],
   "source": [
    "# DOING IMAGE TRANSFORMATION AND WRITING THE AUGMENTED IMAGES INTO RESPECTIVE CATEGORIES\n",
    "\n",
    "# IMPORTING THE LIBRARIES\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_loader(root_dir,batch_size):\n",
    "    my_transforms=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((225,300)),\n",
    "        transforms.RandomCrop((128,128)),\n",
    "        transforms.ColorJitter(brightness=0.5),\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.05),\n",
    "        transforms.RandomGrayscale(p=0.2)\n",
    "    ])\n",
    "\n",
    "    dataset=datasets.ImageFolder(root=root_dir,transform=my_transforms)\n",
    "    class_weights=[]\n",
    "    for root,subdir,files in os.walk(root_dir):\n",
    "        print(root)\n",
    "        if len(files)>0:\n",
    "            class_weights.append(1/len(files))\n",
    "    \n",
    "    sample_weights=[0]*len(dataset)\n",
    "\n",
    "    for idx,(data,label) in enumerate(dataset):\n",
    "        class_weight=class_weights[label]\n",
    "        sample_weights[idx]=class_weight\n",
    "\n",
    "    sampler=WeightedRandomSampler(sample_weights,num_samples=len(sample_weights),replacement=True)\n",
    "\n",
    "    loader=DataLoader(dataset,batch_size=batch_size,sampler=sampler)\n",
    "\n",
    "    return loader\n",
    "\n",
    "loader=get_loader(root_dir=\"classification-assignment\\\\train-exp\",batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lowest=0\n",
    "for e in range(5):\n",
    "    for data,labels in loader:\n",
    "        #print(labels)\n",
    "        if int(labels)==0:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\0.0-3.0-9.0\\\\\"+str(num_lowest)+\"_1.png\")\n",
    "        \n",
    "        if int(labels)==1:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\1.0-3.0-9.0\\\\\"+str(num_lowest)+\"_2.png\")\n",
    "        \n",
    "        if int(labels)==2:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\2.0-3.0-9.0\\\\\"+str(num_lowest)+\"_3.png\")\n",
    "        \n",
    "        if int(labels)==3:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\3.0-3.0-9.0\\\\\"+str(num_lowest)+\"_4.png\")\n",
    "        \n",
    "        if int(labels)==4:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\4.0-3.0-9.0\\\\\"+str(num_lowest)+\"_5.png\")\n",
    "        \n",
    "        if int(labels)==5:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\5.0-3.0-9.0\\\\\"+str(num_lowest)+\"_6.png\")\n",
    "        \n",
    "        if int(labels)==6:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-0.0-9.0\\\\\"+str(num_lowest)+\"_7.png\")\n",
    "        \n",
    "        if int(labels)==7:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-1.0-9.0\\\\\"+str(num_lowest)+\"_8.png\")\n",
    "        \n",
    "        if int(labels)==8:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-2.0-9.0\\\\\"+str(num_lowest)+\"_9.png\")\n",
    "        \n",
    "        if int(labels)==9:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-0.0\\\\\"+str(num_lowest)+\"_10.png\")\n",
    "        \n",
    "        if int(labels)==10:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-1.0\\\\\"+str(num_lowest)+\"_11.png\")\n",
    "\n",
    "        if int(labels)==11:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-2.0\\\\\"+str(num_lowest)+\"_12.png\")\n",
    "        \n",
    "        if int(labels)==12:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-3.0\\\\\"+str(num_lowest)+\"_13.png\")\n",
    "        \n",
    "        if int(labels)==13:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-4.0\\\\\"+str(num_lowest)+\"_14.png\")\n",
    "        \n",
    "        if int(labels)==14:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-5.0\\\\\"+str(num_lowest)+\"_15.png\")\n",
    "        \n",
    "        if int(labels)==15:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-6.0\\\\\"+str(num_lowest)+\"_16.png\")\n",
    "        \n",
    "        if int(labels)==16:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-7.0\\\\\"+str(num_lowest)+\"_17.png\")\n",
    "        \n",
    "        if int(labels)==17:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-8.0\\\\\"+str(num_lowest)+\"_18.png\")\n",
    "        \n",
    "        if int(labels)==18:\n",
    "            save_image(data,\"classification-assignment\\\\train-exp\\\\6.0-3.0-9.0\\\\\"+str(num_lowest)+\"_19.png\")\n",
    "        num_lowest+=1\n",
    "        # print(\"data shape\",data.shape)\n",
    "        # print(\"labels.shape\",labels.shape)\n",
    "        #num_lowest+=torch.sum(labels==\"6.0-3.0-0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5129\n"
     ]
    }
   ],
   "source": [
    "# COUUNTING THE TOTAL NUMBER OF IMAGES\n",
    "count=0\n",
    "for root,subdir,files in os.walk(\"classification-assignment\\\\train-exp\"):\n",
    "        #print(root)\n",
    "        count+=len(files)\n",
    "print(count)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A SIMPLE CNN MODEL AND TRAINING IT ON OUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n",
      "loss at epoch  0 is 2.943\n",
      "loss at epoch  1 is 2.909\n",
      "loss at epoch  2 is 2.915\n",
      "saving model\n",
      "loss at epoch  3 is 2.907\n",
      "loss at epoch  4 is 2.921\n",
      "loss at epoch  5 is 2.924\n",
      "saving model\n",
      "loss at epoch  6 is 2.905\n",
      "loss at epoch  7 is 2.896\n",
      "loss at epoch  8 is 2.886\n",
      "saving model\n",
      "loss at epoch  9 is 2.817\n",
      "loss at epoch  10 is 2.761\n",
      "loss at epoch  11 is 2.748\n",
      "saving model\n",
      "loss at epoch  12 is 2.712\n",
      "loss at epoch  13 is 2.714\n",
      "loss at epoch  14 is 2.675\n",
      "saving model\n",
      "loss at epoch  15 is 2.571\n",
      "loss at epoch  16 is 2.532\n",
      "loss at epoch  17 is 2.429\n",
      "saving model\n",
      "loss at epoch  18 is 2.415\n",
      "loss at epoch  19 is 2.332\n",
      "loss at epoch  20 is 2.279\n",
      "saving model\n",
      "loss at epoch  21 is 2.223\n",
      "loss at epoch  22 is 2.153\n",
      "loss at epoch  23 is 2.126\n",
      "saving model\n",
      "loss at epoch  24 is 2.07\n",
      "loss at epoch  25 is 2.022\n",
      "loss at epoch  26 is 1.984\n",
      "saving model\n",
      "loss at epoch  27 is 1.918\n",
      "loss at epoch  28 is 1.873\n",
      "loss at epoch  29 is 1.85\n",
      "saving model\n",
      "loss at epoch  30 is 1.791\n",
      "loss at epoch  31 is 1.739\n",
      "loss at epoch  32 is 1.716\n",
      "saving model\n",
      "loss at epoch  33 is 1.648\n",
      "loss at epoch  34 is 1.616\n",
      "loss at epoch  35 is 1.59\n",
      "saving model\n",
      "loss at epoch  36 is 1.544\n",
      "loss at epoch  37 is 1.51\n",
      "loss at epoch  38 is 1.488\n",
      "saving model\n",
      "loss at epoch  39 is 1.424\n",
      "loss at epoch  40 is 1.373\n",
      "loss at epoch  41 is 1.387\n",
      "saving model\n",
      "loss at epoch  42 is 1.316\n",
      "loss at epoch  43 is 1.283\n",
      "loss at epoch  44 is 1.285\n",
      "saving model\n",
      "loss at epoch  45 is 1.225\n",
      "loss at epoch  46 is 1.195\n",
      "loss at epoch  47 is 1.182\n",
      "saving model\n",
      "loss at epoch  48 is 1.166\n",
      "loss at epoch  49 is 1.131\n",
      "loss at epoch  50 is 1.068\n",
      "saving model\n",
      "loss at epoch  51 is 1.084\n",
      "loss at epoch  52 is 1.087\n",
      "loss at epoch  53 is 1.006\n",
      "saving model\n",
      "loss at epoch  54 is 0.98\n",
      "loss at epoch  55 is 1.002\n",
      "loss at epoch  56 is 0.97\n",
      "saving model\n",
      "loss at epoch  57 is 0.925\n",
      "loss at epoch  58 is 0.915\n",
      "loss at epoch  59 is 0.902\n",
      "saving model\n",
      "loss at epoch  60 is 0.89\n",
      "loss at epoch  61 is 0.873\n",
      "loss at epoch  62 is 0.841\n",
      "saving model\n",
      "loss at epoch  63 is 0.821\n",
      "loss at epoch  64 is 0.823\n",
      "loss at epoch  65 is 0.822\n",
      "saving model\n",
      "loss at epoch  66 is 0.774\n",
      "loss at epoch  67 is 0.763\n",
      "loss at epoch  68 is 0.772\n",
      "saving model\n",
      "loss at epoch  69 is 0.76\n",
      "loss at epoch  70 is 0.724\n",
      "loss at epoch  71 is 0.724\n",
      "saving model\n",
      "loss at epoch  72 is 0.704\n",
      "loss at epoch  73 is 0.696\n",
      "loss at epoch  74 is 0.695\n",
      "saving model\n",
      "loss at epoch  75 is 0.66\n",
      "loss at epoch  76 is 0.651\n",
      "loss at epoch  77 is 0.66\n",
      "saving model\n",
      "loss at epoch  78 is 0.647\n",
      "loss at epoch  79 is 0.619\n",
      "loss at epoch  80 is 0.619\n",
      "saving model\n",
      "loss at epoch  81 is 0.61\n",
      "loss at epoch  82 is 0.603\n",
      "loss at epoch  83 is 0.599\n",
      "saving model\n",
      "loss at epoch  84 is 0.595\n",
      "loss at epoch  85 is 0.56\n",
      "loss at epoch  86 is 0.58\n",
      "saving model\n",
      "loss at epoch  87 is 0.555\n",
      "loss at epoch  88 is 0.541\n",
      "loss at epoch  89 is 0.558\n",
      "saving model\n",
      "loss at epoch  90 is 0.535\n",
      "loss at epoch  91 is 0.517\n",
      "loss at epoch  92 is 0.529\n",
      "saving model\n",
      "loss at epoch  93 is 0.542\n",
      "loss at epoch  94 is 0.497\n",
      "loss at epoch  95 is 0.493\n",
      "saving model\n",
      "loss at epoch  96 is 0.518\n",
      "loss at epoch  97 is 0.492\n",
      "loss at epoch  98 is 0.508\n",
      "saving model\n",
      "loss at epoch  99 is 0.504\n",
      "Got 4355 / 5129 with accuracy 84.91\n",
      "Got 4355 / 5129 with accuracy 84.91\n"
     ]
    }
   ],
   "source": [
    "# create CNN by modifying our previous network\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # all neural network modules like cnn,linear are there and loss functions are also there\n",
    "import torch.optim as optim # optimizers such as sgd,adam etc\n",
    "import torch.nn.functional as F # relu,tanh etc\n",
    "from torch.utils.data import DataLoader # dataset managaement mini batches etc\n",
    "import torchvision.datasets as datasets # existing datasets\n",
    "import torchvision.transforms as transforms # transformation that can be performed on dataset\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def load_images(image_size=128, batch_size=64, root=\"classification-assignment/train-exp\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    train_set = datasets.ImageFolder(root=root, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "# def save_checkpoint(state,filename=\"my_checkpoint.pth.tar\"):\n",
    "#     print(\"saving model\")\n",
    "#     torch.save(state,filename)\n",
    "\n",
    "# def load_checkpoint(checkpoint):\n",
    "#     print(\"load checkpoint\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,in_channels=3,num_classes=19):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),stride=(1,1),padding=(1,1)) \n",
    "        # last 3 params show same convolution i.e input size equals output size\n",
    "        # formula is nout = (nin+2p-k)/s + 1  (28+2.1-3)/1+1=28\n",
    "        # nin : number of input features, nout : number of output features k: convolution kernel size p: convolution padding size s: convolution stride size\n",
    "\n",
    "        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=32,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1)) \n",
    "        self.fc1=nn.Linear(16*32*32,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x=self.pool(x)\n",
    "        # print(x.shape)\n",
    "        x=F.relu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        x=self.pool(x)\n",
    "        # print(x.shape)\n",
    "        x=x.reshape(x.shape[0],-1) # we need to reshape it because self.conv2 will give us dimensions of shape 4\n",
    "        # print(x.shape)\n",
    "        x=self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "in_channels=3\n",
    "num_classes=19\n",
    "learning_rate=0.0001\n",
    "batch_size=128\n",
    "num_epochs=100\n",
    "load_model=True\n",
    "\n",
    "\n",
    "\n",
    "# Defining variables for use with the CNN.\n",
    "classes = ('0.0-3.0-9.0','1.0-3.0-9.0','2.0-3.0-9.0','3.0-3.0-9.0','4.0-3.0-9.0','5.0-3.0-9.0','6.0-0.0-9.0',\n",
    "            '6.0-1.0-9.0','6.0-2.0-9.0','6.0-3.0-0.0','6.0-3.0-1.0','6.0-3.0-2.0','6.0-3.0-3.0','6.0-3.0-4.0',\n",
    "            '6.0-3.0-5.0','6.0-3.0-6.0','6.0-3.0-7.0','6.0-3.0-8.0','6.0-3.0-9.0')\n",
    "train_loader_data = load_images()\n",
    "\n",
    "# Training samples.\n",
    "n_training_samples = 4629\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "\n",
    "# Validation samples.\n",
    "n_val_samples = 500\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "train_loader = DataLoader(train_loader_data, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = DataLoader(train_loader_data, batch_size=batch_size,\n",
    "                                                sampler=val_sampler)\n",
    "\n",
    "\n",
    "# load data\n",
    "# train_dataset=datasets.MNIST(root=\"dataset/\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "# train_loader=DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n",
    "# test_dataset=datasets.MNIST(root=\"dataset/\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "# test_loader=DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# initialize network\n",
    "model=CNN().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# if load_model: # it will help to start the training from saved checkpoint\n",
    "#     load_model(torch.load(\"my_checkpoint.pth.tar\"))\n",
    "\n",
    "# train network\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    losses=[]\n",
    "    # if epoch % 3 ==0:\n",
    "    #     checkpoint= {'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "    #     save_checkpoint(checkpoint)\n",
    "\n",
    "    for batch_idx,(data,targets) in enumerate(train_loader.dataset):\n",
    "        data=data.to(device=device)\n",
    "        targets=targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores=model(data)\n",
    "        loss=criterion(scores,targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad #set all the gradients to zero for each batch\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step() # update the weights\n",
    "    \n",
    "    mean_loss=sum(losses)/len(losses)\n",
    "    print(\"loss at epoch\",epoch,\"is\",round(mean_loss,3))\n",
    "\n",
    "\n",
    "\n",
    "# check accuracy on training and test to see how good our model is\n",
    "\n",
    "def check_accuracy(loader,model):\n",
    "    # if loader.dataset.train:\n",
    "    #     print(\"checking accuracy on train data\")\n",
    "    # else:\n",
    "    #     print(\"checking accuracy on test data\")\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval() # we want the model to be on evaluation mode\n",
    "\n",
    "    with torch.no_grad(): # dont calculate gradients in case of evaluation it is unecessary calculation\n",
    "        for x,y in loader.dataset:\n",
    "            x=x.to(device=device)\n",
    "            y=y.to(device=device)\n",
    "\n",
    "            scores=model(x)\n",
    "\n",
    "            _,predictions=scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING THE CSV FILE AND RETRIEVING NAN VALUE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A DATAFRAME OF ALL NAN VALUES\n",
    "df=pd.read_csv(\"classification-assignment\\\\attributes_v1.csv\")\n",
    "df_null=df[df.isnull().any(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>neck</th>\n",
       "      <th>sleeve_length</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdc8cd2a-0938-4970-a3b5-f5ed9595222c1527925869...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f7ad67ab-eeb1-4449-8f63-7b580d2797e71532342804...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11505295751483-FOREVER-21-Men-White-Self-Desig...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90044561-8959-460a-a650-49a6772237931537435887...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11520918258005-Vudu-Mens-Casual-Grey-Color-T-S...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>11521699305571-GRITSTONES-Men-Tshirts-20715216...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>5df27174-db94-49ec-bde8-5ca951824d6b1536989188...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>b45143a3-3d48-4f1d-a561-0cc847c5a9e81528972734...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>11489566048379-Parx-Men-Navy-Blue-Solid-Henley...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>8f236dcd-4a2b-49ff-9229-981e7db946f91537273774...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  neck  sleeve_length  \\\n",
       "0    cdc8cd2a-0938-4970-a3b5-f5ed9595222c1527925869...   6.0            NaN   \n",
       "1    f7ad67ab-eeb1-4449-8f63-7b580d2797e71532342804...   NaN            0.0   \n",
       "2    11505295751483-FOREVER-21-Men-White-Self-Desig...   1.0            3.0   \n",
       "3    90044561-8959-460a-a650-49a6772237931537435887...   NaN            NaN   \n",
       "4    11520918258005-Vudu-Mens-Casual-Grey-Color-T-S...   6.0            NaN   \n",
       "..                                                 ...   ...            ...   \n",
       "886  11521699305571-GRITSTONES-Men-Tshirts-20715216...   0.0            NaN   \n",
       "887  5df27174-db94-49ec-bde8-5ca951824d6b1536989188...   NaN            0.0   \n",
       "888  b45143a3-3d48-4f1d-a561-0cc847c5a9e81528972734...   6.0            NaN   \n",
       "889  11489566048379-Parx-Men-Navy-Blue-Solid-Henley...   0.0            3.0   \n",
       "890  8f236dcd-4a2b-49ff-9229-981e7db946f91537273774...   6.0            NaN   \n",
       "\n",
       "     pattern  \n",
       "0        4.0  \n",
       "1        9.0  \n",
       "2        NaN  \n",
       "3        9.0  \n",
       "4        9.0  \n",
       "..       ...  \n",
       "886      NaN  \n",
       "887      9.0  \n",
       "888      9.0  \n",
       "889      NaN  \n",
       "890      5.0  \n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESETTING THEIR INDEXES\n",
    "df[df.isnull().any(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICITNG THE NAN IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMING PREDICTION ON EACH NAN IMAGES AND STORING THEM INTO THEIR RESPECTIVE CLASS FOLDERS\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def predict_single(img_path,model,num_lowest):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    img_processed = transform(img)\n",
    "    img_processed=img_processed.unsqueeze(0)\n",
    "    print(img_processed.shape)\n",
    "    model.eval() # we want the model to be on evaluation mode\n",
    "\n",
    "    with torch.no_grad(): # dont calculate gradients in case of evaluation it is unecessary calculation\n",
    "        img_processed=img_processed.to(device=device)\n",
    "        scores=model(img_processed)\n",
    "        _,predictions=scores.max(1)\n",
    "    \n",
    "    if int(predictions)==0:\n",
    "        #shutil.copyfile(img_path, \"classification-assignment\\\\train-exp\\\\0.0-3.0-9.0\\\\\"+str(num_lowest)+\"_1.png\")\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\0.0-3.0-9.0\\\\\"+str(num_lowest)+\"_1.png\")\n",
    "    \n",
    "    if int(predictions)==1:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\1.0-3.0-9.0\\\\\"+str(num_lowest)+\"_2.png\")\n",
    "    \n",
    "    if int(predictions)==2:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\2.0-3.0-9.0\\\\\"+str(num_lowest)+\"_3.png\")\n",
    "    \n",
    "    if int(predictions)==3:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\3.0-3.0-9.0\\\\\"+str(num_lowest)+\"_4.png\")\n",
    "    \n",
    "    if int(predictions)==4:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\4.0-3.0-9.0\\\\\"+str(num_lowest)+\"_5.png\")\n",
    "    \n",
    "    if int(predictions)==5:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\5.0-3.0-9.0\\\\\"+str(num_lowest)+\"_6.png\")\n",
    "    \n",
    "    if int(predictions)==6:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-0.0-9.0\\\\\"+str(num_lowest)+\"_7.png\")\n",
    "    \n",
    "    if int(predictions)==7:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-1.0-9.0\\\\\"+str(num_lowest)+\"_8.png\")\n",
    "    \n",
    "    if int(predictions)==8:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-2.0-9.0\\\\\"+str(num_lowest)+\"_9.png\")\n",
    "    \n",
    "    if int(predictions)==9:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-0.0\\\\\"+str(num_lowest)+\"_10.png\")\n",
    "    \n",
    "    if int(predictions)==10:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-1.0\\\\\"+str(num_lowest)+\"_11.png\")\n",
    "\n",
    "    if int(predictions)==11:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-2.0\\\\\"+str(num_lowest)+\"_12.png\")\n",
    "    \n",
    "    if int(predictions)==12:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-3.0\\\\\"+str(num_lowest)+\"_13.png\")\n",
    "    \n",
    "    if int(predictions)==13:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-4.0\\\\\"+str(num_lowest)+\"_14.png\")\n",
    "    \n",
    "    if int(predictions)==14:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-5.0\\\\\"+str(num_lowest)+\"_15.png\")\n",
    "    \n",
    "    if int(predictions)==15:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-6.0\\\\\"+str(num_lowest)+\"_16.png\")\n",
    "    \n",
    "    if int(predictions)==16:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-7.0\\\\\"+str(num_lowest)+\"_17.png\")\n",
    "    \n",
    "    if int(predictions)==17:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-8.0\\\\\"+str(num_lowest)+\"_18.png\")\n",
    "    \n",
    "    if int(predictions)==18:\n",
    "        shutil.copyfile(img_path,\"classification-assignment\\\\train-exp\\\\6.0-3.0-9.0\\\\\"+str(num_lowest)+\"_19.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE SAVED MODEL AND ITERATING ON EACH NAN IMAGES FOR PREDICTION\n",
    "def load_checkpoint(checkpoint):\n",
    "    print(\"load checkpoint\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"))\n",
    "for i in range(len(df_null['filename'])):\n",
    "    #print(df_null['filename'][i])\n",
    "    predict_single(\"classification-assignment\\\\images\\\\\"+df_null['filename'][i],model,\"nan_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "328\n",
      "357\n",
      "336\n",
      "330\n",
      "388\n",
      "332\n",
      "320\n",
      "330\n",
      "330\n",
      "277\n",
      "309\n",
      "272\n",
      "282\n",
      "307\n",
      "282\n",
      "291\n",
      "244\n",
      "299\n",
      "406\n",
      "6020\n"
     ]
    }
   ],
   "source": [
    "# TAKING COUNT OF ALL CATEGORIES\n",
    "count=0\n",
    "for root,subdir,files in os.walk(\"classification-assignment\\\\train-exp\"):\n",
    "        print(len(files))\n",
    "        count+=len(files)\n",
    "print(count)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n",
      "loss at epoch 0 is 2.975\n",
      "loss at epoch 1 is 2.907\n",
      "loss at epoch 2 is 2.891\n",
      "saving model\n",
      "loss at epoch 3 is 2.885\n",
      "loss at epoch 4 is 2.867\n",
      "loss at epoch 5 is 2.889\n",
      "saving model\n",
      "loss at epoch 6 is 2.88\n",
      "loss at epoch 7 is 2.843\n",
      "loss at epoch 8 is 2.777\n",
      "saving model\n",
      "loss at epoch 9 is 2.722\n",
      "loss at epoch 10 is 2.689\n",
      "loss at epoch 11 is 2.601\n",
      "saving model\n",
      "loss at epoch 12 is 2.477\n",
      "loss at epoch 13 is 2.357\n",
      "loss at epoch 14 is 2.25\n",
      "saving model\n",
      "loss at epoch 15 is 2.112\n",
      "loss at epoch 16 is 2.036\n",
      "loss at epoch 17 is 1.94\n",
      "saving model\n",
      "loss at epoch 18 is 1.802\n",
      "loss at epoch 19 is 1.771\n",
      "loss at epoch 20 is 1.665\n",
      "saving model\n",
      "loss at epoch 21 is 1.584\n",
      "loss at epoch 22 is 1.52\n",
      "loss at epoch 23 is 1.455\n",
      "saving model\n",
      "loss at epoch 24 is 1.382\n",
      "loss at epoch 25 is 1.297\n",
      "loss at epoch 26 is 1.282\n",
      "saving model\n",
      "loss at epoch 27 is 1.225\n",
      "loss at epoch 28 is 1.151\n",
      "loss at epoch 29 is 1.121\n",
      "saving model\n",
      "loss at epoch 30 is 1.083\n",
      "loss at epoch 31 is 1.05\n",
      "loss at epoch 32 is 0.987\n",
      "saving model\n",
      "loss at epoch 33 is 0.973\n",
      "loss at epoch 34 is 0.904\n",
      "loss at epoch 35 is 0.897\n",
      "saving model\n",
      "loss at epoch 36 is 0.848\n",
      "loss at epoch 37 is 0.827\n",
      "loss at epoch 38 is 0.812\n",
      "saving model\n",
      "loss at epoch 39 is 0.78\n",
      "loss at epoch 40 is 0.738\n",
      "loss at epoch 41 is 0.744\n",
      "saving model\n",
      "loss at epoch 42 is 0.692\n",
      "loss at epoch 43 is 0.677\n",
      "loss at epoch 44 is 0.703\n",
      "saving model\n",
      "loss at epoch 45 is 0.615\n",
      "loss at epoch 46 is 0.631\n",
      "loss at epoch 47 is 0.618\n",
      "saving model\n",
      "loss at epoch 48 is 0.567\n",
      "loss at epoch 49 is 0.559\n",
      "loss at epoch 50 is 0.559\n",
      "saving model\n",
      "loss at epoch 51 is 0.5\n",
      "loss at epoch 52 is 0.508\n",
      "loss at epoch 53 is 0.512\n",
      "saving model\n",
      "loss at epoch 54 is 0.477\n",
      "loss at epoch 55 is 0.466\n",
      "loss at epoch 56 is 0.459\n",
      "saving model\n",
      "loss at epoch 57 is 0.445\n"
     ]
    }
   ],
   "source": [
    "# AGAIN CREATING OUR CNN MODEL AND TRAINING IT ON NEW DATASET AND SAVING THE NEW MODEL FILE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # all neural network modules like cnn,linear are there and loss functions are also there\n",
    "import torch.optim as optim # optimizers such as sgd,adam etc\n",
    "import torch.nn.functional as F # relu,tanh etc\n",
    "from torch.utils.data import DataLoader # dataset managaement mini batches etc\n",
    "import torchvision.datasets as datasets # existing datasets\n",
    "import torchvision.transforms as transforms # transformation that can be performed on dataset\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def load_images(image_size=128, batch_size=64, root=\"classification-assignment/train-exp\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    train_set = datasets.ImageFolder(root=root, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def save_checkpoint(state,filename=\"my_checkpoint_include_nan.pth.tar\"):\n",
    "    print(\"saving model\")\n",
    "    torch.save(state,filename)\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    print(\"load checkpoint\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,in_channels=3,num_classes=19):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),stride=(1,1),padding=(1,1)) \n",
    "        # last 3 params show same convolution i.e input size equals output size\n",
    "        # formula is nout = (nin+2p-k)/s + 1  (28+2.1-3)/1+1=28\n",
    "        # nin : number of input features, nout : number of output features k: convolution kernel size p: convolution padding size s: convolution stride size\n",
    "\n",
    "        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=32,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1)) \n",
    "        self.fc1=nn.Linear(16*32*32,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x=self.pool(x)\n",
    "        # print(x.shape)\n",
    "        x=F.relu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        x=self.pool(x)\n",
    "        # print(x.shape)\n",
    "        x=x.reshape(x.shape[0],-1) # we need to reshape it because self.conv2 will give us dimensions of shape 4\n",
    "        # print(x.shape)\n",
    "        x=self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "in_channels=3\n",
    "num_classes=19\n",
    "learning_rate=0.0001\n",
    "batch_size=128\n",
    "num_epochs=100\n",
    "load_model=True\n",
    "\n",
    "\n",
    "\n",
    "# Defining variables for use with the CNN.\n",
    "classes = ('0.0-3.0-9.0','1.0-3.0-9.0','2.0-3.0-9.0','3.0-3.0-9.0','4.0-3.0-9.0','5.0-3.0-9.0','6.0-0.0-9.0',\n",
    "            '6.0-1.0-9.0','6.0-2.0-9.0','6.0-3.0-0.0','6.0-3.0-1.0','6.0-3.0-2.0','6.0-3.0-3.0','6.0-3.0-4.0',\n",
    "            '6.0-3.0-5.0','6.0-3.0-6.0','6.0-3.0-7.0','6.0-3.0-8.0','6.0-3.0-9.0')\n",
    "train_loader_data = load_images()\n",
    "\n",
    "# Training samples.\n",
    "n_training_samples = 6020\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "\n",
    "# Validation samples.\n",
    "n_val_samples = 500\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "train_loader = DataLoader(train_loader_data, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = DataLoader(train_loader_data, batch_size=batch_size,\n",
    "                                                sampler=val_sampler)\n",
    "\n",
    "\n",
    "# load data\n",
    "# train_dataset=datasets.MNIST(root=\"dataset/\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "# train_loader=DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n",
    "# test_dataset=datasets.MNIST(root=\"dataset/\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "# test_loader=DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# initialize network\n",
    "model=CNN().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# if load_model: # it will help to start the training from saved checkpoint\n",
    "#     load_model(torch.load(\"my_checkpoint_include_nan.pth.tar\"))\n",
    "\n",
    "# train network\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    losses=[]\n",
    "    if epoch % 3 ==0:\n",
    "        checkpoint= {'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    for batch_idx,(data,targets) in enumerate(train_loader.dataset):\n",
    "        data=data.to(device=device)\n",
    "        targets=targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores=model(data)\n",
    "        loss=criterion(scores,targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad #set all the gradients to zero for each batch\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step() # update the weights\n",
    "    \n",
    "    mean_loss=sum(losses)/len(losses)\n",
    "    print(\"loss at epoch\",epoch,\"is\",round(mean_loss,3))\n",
    "\n",
    "\n",
    "\n",
    "# check accuracy on training and test to see how good our model is\n",
    "\n",
    "def check_accuracy(loader,model):\n",
    "    # if loader.dataset.train:\n",
    "    #     print(\"checking accuracy on train data\")\n",
    "    # else:\n",
    "    #     print(\"checking accuracy on test data\")\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval() # we want the model to be on evaluation mode\n",
    "\n",
    "    with torch.no_grad(): # dont calculate gradients in case of evaluation it is unecessary calculation\n",
    "        for x,y in loader.dataset:\n",
    "            x=x.to(device=device)\n",
    "            y=y.to(device=device)\n",
    "\n",
    "            scores=model(x)\n",
    "\n",
    "            _,predictions=scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d57f83d84ff091c523e40add7b0937cccb0f101ec49b615a97907892197b0edc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('localenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
